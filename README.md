Robust Android Malware Detection Against Adversarial
==============

# Description of directory structure 

├── Readme.md　　　　　　　　　　// help 


├── feature　　　　　　　　　　　// the features used in paper 

&emsp;&emsp;├── list_total_actions.txt　　　　　　　　　　// the actions list 

&emsp;&emsp;├── list_total_apis.txt　　　　　　　　　　　// the apis list 

&emsp;&emsp;└── list_total_permissions.txt　　　　　　　// the permissions list 

# Some complemented descriptions

## **1. Can our method be used in the other domains such as PDF malware detection?**

Yes. Our method can be extended to the other domains with binary features, e.g., PDF malware detection. To show it, we conduct some experiments on the PDF dataset. We employed the method in Hidost [<sup>[1]</sup>](#refer-anchor-1) to extract path features from Contagio [<sup>[2]</sup>](#refer-anchor-2), which is a dataset contains 10344 malicious pdf samples and 8994 benign pdf samples. We use 6896 malicious samples and 6296 benign samples to train our model and the rest samples for evaluation.

We use three methods to generate adversarial pdf malware. The first method is to generate perturbations basing on the gradient information iteratively, i.e, I-FGSM. Furthermore, we use the methods in [<sup>[3]</sup>](#refer-anchor-3)[<sup>[4]</sup>](#refer-anchor-4) to generate adversarial pdf malware. 

We also implement an MLP classifier containing three hidden layers as the baseline model.

We evaluate the recall rate and precision rate of the two mentioned models on the test dataset. Moreover, we evaluate the two models’ accuracy on the adversarial modified malware feature vectors. As shown in the following table, our model can achieve a high accuracy under I-FGSM, APDNN and MalGAN, and hence it detects adversarial attacks effectively. 
           
+ **Table1 Classifier Performance evaluation**


|                            | Recall  | Precision | I-FGSM  | APDNN   | MalGAN   |
| -------------------------- | ------- | --------- | ------- | ------- | -------- |
| MLP                        | 99.97% | 99.92%   | 0.03%  | 0.06%  | 0.00%   |
| Our method (threshold=254) | 99.97% | 99.11%   | 99.97% | 91.13% | 100.00% |

<div id="refer-anchor-1"></div>
[1] [Hidost: Toolset for extracting document structures from PDF and SWF files](https://github.com/srndic/hidost)
[uiukjk](https://github.com/srndic/hidost)
<div id="refer-anchor-2"></div>
[2] [M. Parkour. 16,800 clean and 11,960 malicious files for signature testing and research](http://contagiodump.blogspot.com/2013/03/16800-clean-and-11960-maliciousfiles.html)
<div id="refer-anchor-3"></div>
[3] [Ishai Rosenberg, Asaf Shabtai, Lior Rokach, and Yuval Elovici. 2018. Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers. In Proc. International Symposium on Research in Attacks. 490–510]()
<div id="refer-anchor-4"></div>
[4] [Weiwei Hu and Ying Tan. 2017. Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN. arXiv: 1702.05983 (2017)]()

## **2. How do we extract the features from an apk file?**

The features used by our method include permissions, intent actions and API calls. Given an app, we extract these features from the corresponding APK file. The main procedure of feature extraction is briefly depicted as follows. 

+ **1) Unpack the APK file**. We unpack the APK file, and then get the Manifest (AndroidManifest.xml), Dalvik Bytecode (class.dex) and other resource files. The Dalvik Bytecode is compiled and assembled from all Java source codes of an APP. Manifest declares the essential information, such as permission requirements. 

+ **2) Decompile classes.dex**. The class.dex file obtained in the first step is binary, and hence cannot be processed directly. To tackle this problem, we use apktool (https://ibotpeaches.github.io/Apktool/) to decompile classes.dex into *.smali files, and translate AndroidManifest.xml into AndroidManifest.txt. Here apktool is a tool that can decode Android resources to the nearly original form and rebuild them after making some modifications.

+ **3) Obtain features**. Finally, we extracte 106 sensitive API calls from the *.smali files, and 147 permissions, 126 intent actions from the AndroidManifest.txt. We then vectorize them as a 379-dimensional binary vector, in which every “1” means the corresponding permission/ action/API is called/requested/registered, and every “0” indicates the opposite case. More details about these features can be found in the fold “feature”.

## **3. Why does the detection probability of our method for MalGAN arise as rounds increase?**

+ **1)** It is the collapse of GAN that results in the phenomenon noted by Reviewer 3. In a GAN, Generator and Discriminator keep evolving only when the balance between them is well maintained. If Discriminator dominates Generator, GAN will perform worse and worse, and finally walk to collapse. 

+ **2)** Generator is dominated by Discriminator, because the AE defense mechanisms (e.g., RT) strengthen the target classifiers, and push their decision boundaries closer to the ideal boundary. When the difference between decision boundary and ideal boundary is small, Generator fails to generate proper perturbations that can stride over the decision boundary but does not exceed the ideal boundary. Accordingly, generating AEs becomes extremely difficult, making Generator perform poorly and dominated by Discriminator.

+ **3)** Why do defense mechanisms reduce the boundary difference? For example, RT (robust training) uses some collected AEs to train an existing classifier. Guided by these AEs, RT partially modifies the decision boundary, in order to make it approach the ideal boundary. 

## **4. Why does our method perform better on E-MalGAN than on MalGAN?**

+ **1)** MalGAN has one Discriminator. But E-MalGAN has two Discriminators. The first is used to simulate the target classifier, and the second is used to distinguish the generated AEs from natural examples. The introduction of two Discriminators is a two-edged sword. Aided by the second Discriminator, E-MalGAN can generate the AEs highly similar to natural examples. Therefore, E-MalGAN succeeds in misleading the existing classifiers with defenses (e.g., dFGSM_RT). On the other hand, the training unstability risk of E-MalGAN is also raised by the introduction of two Discriminators, especially when faced with a challenging AE generation task. 

+ **2)** E-MalGAN encounters failure on our method. Different from the existing defense mechanisms, our method pushes the whole (instead of a part of) decision boundary to the ideal boundary using feature disentangle. Therefore, generating AEs becomes much more challenging. Faced such a challenging task, E-MalGAN becomes very unstable and collapses soon. Therefore E-MalGAN is easily beaten by our method. 

+ **3)** If we weaken the defending capability of our method through enhancing the threshold v, the AE generation task became easier for E-MalGAN. Under this situation, the detection probability for E-MalGAN fells lower than 100%. To support this viewpoint, we conduct many experiments, where we gradually increase the threshold. Recall that we use a VAE to reconstruct the inputs. If the reconstruction error exceeds the threshold, the input is detected to be malicious. Therefore, when we increase the threshold, the defending capability of our method is weakened. Accordingly, the detection probability of our method should be decreased. Our experimental results confirm it. Fig. 1 shows how the detection probability varies with rounds of E-MalGAN, under four different thresholds (i.e., 30, 300, 320 and 350). The x-ray denotes the number of rounds. The y-ray represents R-AEI, i.e., the detection probability of AEs. It can be seen that with a too large threshold (e.g., 350), R-AEI falls below 100%, which means E-MalGAN beats our method. When the threshold is appropriately chosen (e.g., 30), R-AEI keeps 100% within over 500 rounds. In addition, it was observed in our experiments that multiple thresholds result in a detection probability of 100%.

![experiments on various threshold](https://i.loli.net/2020/12/01/lqgZoQpahDGXdei.png "Fig. 1 experiments on various thresholds")
