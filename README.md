# Robust Android Malware Detection Against Adversarial

\# Robust Android Malware Detection Against Adversarial

 

\############ Description of directory structure 

├── Readme.md                // help 

├── feature                 // the features used in paper 

   ├── list_total_actions.txt       // the actions list 

   ├── list_total_apis.txt         // the apis list 

   └── list_total_permissions.txt     // the permissions list 









\############ Some complemented descriptions

 

**1. Can our method be used in the other domains such as PDF malware detection?**

Our method can be extended to the other domains with binary features, e.g., PDF malware detection. To show it, we conduct some experiments on PDF dataset. Based on the codes in [1], we implement a PDF classifier through following the method proposed in our manuscript.

The dataset ... is briefly introduced as follows. ..

The adversarial example (AE) methods used in our experiments are described below. 

Our experimental results are given in Table1. It can be seen that our classifier can effectively resist the AE attacks. As a result, the method proposed in our manuscript is applicable to the domains such as PDF malware detection. 

 

[1] On Training Robust PDF Malware Classifiers. Usenix Security. 2020

​                                       **Table1 Classifier Performance evaluation**


| Accuracy           | No_defense | Our method |
| ------------------ | ---------- | ---------- |
| origianl           |            |            |
| Attact_Method1 [1] |            |            |
| Attact_Method2 [1] |            |            |
| Attact_Method3 [2] |            |            |



**2. How do we extract the features from an apk file?**

The features used by our method include permissions, intent actions and API calls. Given an app, we extract these features from the corresponding APK file. The main procedure of feature extraction is briefly depicted as follows. 

(1) **Unpack the APK file**. We unpack the APK file, and then get the Manifest (AndroidManifest.xml), Dalvik Bytecode (class.dex) and other resource files. The Dalvik Bytecode is compiled and assembled from all Java source codes of an APP. Manifest declares the essential information, such as permission requirements. 

(2) **Decompile classes.dex **The class.dex file obtained in the first step is binary, and hence cannot be processed directly. To tackle this problem, we use apktool (https://ibotpeaches.github.io/Apktool/) to decompile classes.dex into *.smali files, and translate AndroidManifest.xml into AndroidManifest.txt. Here apktool is a tool that can decode Android resources to the nearly original form and rebuild them after making some modifications. 

**Obtain features**. Finally, we extracted 106 sensitive API calls from the *.smali files, and 147 permissions, 126 intent actions from the AndroidManifest.txt. We then vectorize them as a 379-dimensional binary vector, in which every “1” means the corresponding permission/ action/API is called/requested/registered, and every “0” indicates the opposite case. More details about these features can be found in the fold “feature”.

 

**3. Why does our method perform better on E-MalGAN than on MalGAN? Furthermore, why does the detection probability arise as rounds increase?**

 

The existence of malware AEs is due to the imperfect decision boundary of a target classifier. If the decision boundary is very close to the perfect or ideal boundary, generating AEs becomes extremely difficult. 

(1) In a GAN, Generator and Discriminator keep evolving only when the balance between them is well maintained. If Discriminator dominates Generator, GAN may walk to collapse and performs poorly. 

(2) When defense mechanisms are adopted, the decision boundary of target classifiers (e.g., rFGSM_RT) becomes closer to the ideal boundary. For example, RT (robust training) uses some AEs to train the classifier. This operation partially modifies the decision boundary of classifier and pushes it closer to the ideal boundary. Under this situation, finding AEs becomes very difficult for Generator. Therefore, Generator is dominated by Discriminator, making GANs (e.g., MalGAN) walk to collapse and produce poor samples. This explains why our detection probability arises when rounds increase.    

(3) Different from MalGAN, E-MalGAN can beat the classical defense mechanisms (e.g., AR and RT). To generate AEs that can circumvent malware detection, MalGAN employs one Discriminator to simulate its target classifier. In addition to simulating its target classifier, E-MalGAN also adopts another Discriminator to distinguish the generated AEs from natural examples. Aided by the second discriminator, E-MalGAN can generate the AEs highly similar to natural examples. Therefore, E-MalGAN succeeds in cheating the existing classifiers even if they are equipped with defense mechanisms (e.g., AR and RT). But E-MalGAN cannot cheat our classifier. Our decision boundary is very close to the ideal boundary owning to feature disentangle. Accordingly, E-MalGAN cannot find appropriate perturbations making its samples stride over the decision boundary. 

(4) Why does our method perform better on E-MalGAN than on MalGAN? First, our method differs from the existing AE defenses (e.g., AR and RT), since our method push the whole (instead of a part of) decision boundary closer to the ideal boundary. Hence generating AEs becomes much more challenging for Generator. Second, the Generator of E-MalGAN is guided by two Discriminators. When facing a too challenging task, the training of E-MalGAN becomes more unstable. And this explains why E-MalGAN is easily beaten by our method. In fact, we have conducted more experiments. When we enhanced the threshold v, the AE defending capability of our method was weaken. Accordingly, the AE generation task became easier. Under this situation, the detection probability of our method fell lower than 100% on E-MalGAN. 

(5) To verify the analyses above, here we provide some experimental results on various thresholds against E-MalGAN. In these experiments, we gradually increase the threshold. Recall that we use a VAE to reconstruct the inputs. If the reconstruction error exceeds the threshold, the input is detected to be malicious. Therefore, when we increase the threshold, the defending capability of our method is weakened. Accordingly, the detection probability of AEs should be decreased. Our experimental results confirm it. Fig. 1 shows how the detection probability of AEs varies with rounds of E-MalGAN, under five different thresholds (i.e., 30, 300, 310, 350, and 600). The x-ray denotes the number of rounds. The y-ray represents R-AEI, i.e., the detection probability of AEs. It can be seen that with a too large threshold, R-AEI keeps decreasing and finally approaches zero, which means E-MalGAN has collapsed. When the threshold is appropriately chosen (e.g., 30), R-AEI remains flat when E-MalGAN is being trained for over 500 rounds. In our experiments, it was observed that the curve of R-AEI remained flat and approached 100% when multiple thresholds were chosen (e.g., 30, 35, 40, 45, 50 and 60). 

![img](https://i.loli.net/2020/12/01/lqgZoQpahDGXdei.png)