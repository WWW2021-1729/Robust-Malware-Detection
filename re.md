We sincerely thank all reviewers for their comments. 

**Reviewer 1**

1. Is our model applicable to other domains (e.g., PDF malwares)

**Response**: Our model is applicable to the domains using discrete features for detection, including PDF malware detection. Some results on PDF malware detection are shown on https://github.com/Henry-0811/Robust-Android-Malware-Detection-Against-Adversarial.

 

2. Are the AE generation techniques and defense mechanisms (AR, RT etc.) are state-of-the-art?

**Response:** Thanks a lot. The white-box attack methods used in our manuscript have been widely used in top conference/journal (e.g., [1][2]) papers. The black-box attack methods MalGAN and E-MalGAN are recently proposed. To our knowledge, E-MalGAN is the latest black-box attack method for Android malware detectors. As for the defense mechanisms such as AR and RT, they have also been used in existing literature including CVPR 2020, TIFS 2020 and Usenix Security 2020. 

[1] Efficient Adversarial Training with Transferable Adversarial Examples. Cvpr, 2020.

[2] On Training Robust PDF Malware Classifiers. Usenix Security, 2020

 

3. Related work section needs to be rewritten. A brief description of the AE generation techniques (e.g., dFGSMk and rFGSMk) could be helpful.

**Response:** Thanks. We will rewrite the section of related work and add more descriptions in the revised manuscript.

 

4. The reasoning behind threshold(v) selection in Sec. 4.5 is a bit vague. 

**Response:** Thanks. In this section, we select a desired threshold through evaluating all candidate thresholds in malware detection and AE detection. Fig. 9 reflects how these thresholds perform in distinguishing malware from begin apps. Fig. 10 shows how they perform in identifying AEs and normal examples. It can be seen that the threshold 30 achieves satisfactory FA, MD, and detection accuracies. Therefore, this threshold is chosen by us. In the revised manuscript, we will rewrite this section to make it clearer. 

 

5. The paper should refer to the sections using their numbers and not titles.

**Response**: Thanks. We will revise our manuscript according to this comment.

 

 

**Reviewer 2**

1. How do the authors choose these features?

**Response**:

Thanks a lot. Similar to [1], we choose 379 features including permissions, intent actions and API calls. In fact, we conducted many experiments over different feature sets, and finally selected them due to their excellent performance. We show the details of these features and describe how to extract these features from an apk file in https://github.com/Henry-0811/Robust-Android-Malware-Detection-Against-Adversarial. 

[1] A Lightweight On-device Detection Method for Android Malware. IEEE Trans. SMC: Systems, 2019.

 

2. No comparison is offered with popular tools such as DREBIN and Mamadroid. 

**Response**:

We really appreciate this comment. The main idea of our manuscript is to study malware detection and AE defense in a joint fashion. DREBIN and Mamaroid are excellent detectors, but they do not consider AE defense. In addition, both malware detection and AE generation heavily depend on the features. Since DREBIN and Mamadroid use the features different from ours, it is hard to directly compare them with our method. 

 

3. Several similar works are not even mentioned. 

**Response**: Thanks. We will add the discussions on them into the revised manuscript.

 

4. This paper seems a bit out of scope for what concerns the WWW CFP. 



**Response**: Thanks. Before submitting our manuscript, we found several www 2020 papers that study Android malware and adversarial examples. For example, the best student paper of www 2020 is “Mobile App Squatting”, which focuses on Android malware and explores the squatting attacks in Android apps.

 

5. There is no mention of any code or dataset release. 

**Response**:

The code and dataset will be released later. The list of permissions/intent/APIs used as features is shown at  https://github.com/Henry-0811/Robust-Android-Malware-Detection-Against-Adversarial. 

 

6. Minor: there are many typos and spelling errors.

**Response**:

We will improve the presentation quality of our manuscript.

 

**Reviewer 3**

 

1. [Q1] Was any obfuscation present in the malicious training data examples? If obfuscation was present, could this obfuscation have been achieved by malGAN or E-MalGAN?

**Response**: Thanks for your careful consideration. In our experiments, no adversarial examples (AEs) were chosen as training data. There is no obfuscation in the malicious training data examples. In addition, no overfitting is found in our experiments. We will release the code and dataset in github.

 

2. [Q2] How are defense mechanisms detecting MalGAN and E-MalGAN with a higher probability as the rounds increase? Why does the proposed method perform better on E-MalGAN than on MalGAN?

**Response**: We really appreciate this comment. 

1) The existence of malware AEs is due to the fact that the decision boundary of a target classifier is imperfect. If the decision boundary is very close to the perfect or ideal boundary, generating AEs becomes extremely difficult. 

2) In a GAN, Generator and Discriminator keep evolving only when the balance between them is well maintained. If Discriminator dominates Generator, GAN may finally walk to collapse and cannot produce good samples. 

3) When defense mechanisms are adopted, the decision boundary of target classifiers (e.g., rFGSM_RT) becomes closer to the ideal boundary. Under this situation, finding AEs becomes very difficult for Generator. Therefore, Generator is dominated by Discriminator, making GANs (e.g., MalGAN) finally walk to collapse and produce poor samples.   

4) Why can E-MalGAN beat the classical defense mechanisms (e.g., AR and RT)? To generate adversarial examples (AEs) that can circumvent malware detection, MalGAN employs one discriminator to simulate its target classifier. In addition to simulating its target classifier, E-MalGAN also adopts another discriminator to distinguish the generated AEs from natural examples. Aided by the second discriminator, E-MalGAN can generate the AEs highly similar to natural examples. Therefore, E-MalGAN succeeds in cheating the existing classifiers even if they are equipped with defense mechanisms. But E-MalGAN cannot cheat our classifier, because our decision boundary is very close to the ideal boundary due to the introduction of feature disentangle. Accordingly, E-MalGAN cannot find the appropriate perturbations making its samples stride over the decision boundary. 

5) Why does our method performs better on E-MalGAN than on MalGAN? As mentioned above, E-MalGAN generates the AEs highly similar to natural examples. Experiments show that E-MalGAN generates much smaller perturbations than MalGAN does. However, the pursuit of smaller perturbations makes E-MalGAN weaker in cheating classifiers. More specifically, smaller perturbations make E-MalGAN harder to stride over the decision boundary of our classifier. This accounts for why E-MalGAN is easily defended by our method. Furthermore, our method does not detect AEs at all. Therefore, the main consideration of E-MalGAN (i.e., evading AE detection) becomes useless for our method.

 

3. [Q3] How does this work compare with [1]? 

**Response:**

Thanks. [1] points out an interesting direction which detects apps by judging whether the behavior of ICONS in an app is the same as the permissions required for it. Our method does not require running an app, and hence it does not use the icon information. So we do not compare our method with [1]. 

 

 

4.The evaluation section requires a better organization, and the related work section did not provide a clear point as to how the proposed mechanism differentiates from previous work

**Response**: Thanks a lot. We will rewrite the sections of evaluation and related work in the revised paper. 

 

5. In Fig. 6, the red dotted line is not included.

**Response**: Thanks. The red dotted line does exists, but is not easy to find. In the revised paper, we will redraw this figure and strengthen this line. 

 